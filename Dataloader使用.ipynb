{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DataLoader用法\n",
    "        -　使用流程\n",
    "            ① 创建一个 Dataset 对象\n",
    "            ② 创建一个 DataLoader 对象\n",
    "            ③ 循环这个 DataLoader 对象\n",
    "        -　参数\n",
    "            dataset(Dataset): 传入的数据集\n",
    "            batch_size(int, optional): 每个batch有多少个样本\n",
    "            shuffle(bool, optional): 在每个epoch开始的时候，对数据进行重新排序\n",
    "            sampler(Sampler, optional): 自定义从数据集中取样本的策略，如果指定这个参数，那么shuffle必须为False\n",
    "            batch_sampler(Sampler, optional): 与sampler类似，但是一次只返回一个batch的indices（索引），需要注意的是，一旦指定了这个参数，那么batch_size,shuffle,sampler,drop_last就不能再制定了（互斥——Mutually exclusive）\n",
    "            num_workers (int, optional): 这个参数决定了有几个进程来处理data loading。0意味着所有的数据都会被load进主进程。（默认为0）\n",
    "            collate_fn (callable, optional): 将一个list的sample组成一个mini-batch的函数\n",
    "            pin_memory (bool, optional)： 如果设置为True，那么data loader将会在返回它们之前，将tensors拷贝到CUDA中的固定内存（CUDA pinned memory）中.\n",
    "            drop_last (bool, optional): 如果设置为True：这个是对最后的未完成的batch来说的，比如你的batch_size设置为64，而一个epoch只有100个样本，那么训练的时候后面的36个就被扔掉了…如果为False（默认），那么会继续正常执行，只是最后的batch_size会小一点。\n",
    "            timeout(numeric, optional): 如果是正数，表明等待从worker进程中收集一个batch等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容了。这个numeric应总是大于等于0。默认为0\n",
    "            worker_init_fn (callable, optional): 每个worker初始化函数 If not None, this will be called on each\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"使用体会\n",
    "    1. 自定义创建一个class，来定义Dataset对象\n",
    "        - 其中，这个class至少包含3个函数：\n",
    "            - __init__：传入数据\n",
    "            - __len__：返回数据集中一共有多少个数据\n",
    "            - __getitem__：返回一条训练数据，并将其转换成tensor（对数据的预处理可以放在此处进行）\n",
    "    2. 使用DataLoader给数据集设置一定的规则，然后送入训练\n",
    "    3. 根据划分好的数据进行循环：在for循环中使用enumerate()来枚举遍历数据。注意，每次枚举遍历的是根据batch_size划分后的数据集合\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = open(data_path, 'r', encoding='utf-8').readlines()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ['4\\n', '2\\n', '11\\n', '6\\n']) 12\n",
      "(1, ['8\\n', '12', '7\\n', '5\\n']) 12\n",
      "(2, ['9\\n', '1\\n', '3\\n', '10\\n']) 12\n",
      "#####################\n",
      "(0, ['3\\n', '2\\n', '4\\n', '5\\n']) 12\n",
      "(1, ['11\\n', '6\\n', '10\\n', '12']) 12\n",
      "(2, ['7\\n', '1\\n', '8\\n', '9\\n']) 12\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomDataset('dataset.txt')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "\n",
    "for i in range(2):\n",
    "    for item in enumerate(train_loader):\n",
    "        print(item)\n",
    "#         print(item, len(train_loader.dataset))  # train_loader.dataset表示数据集的总长度\n",
    "    print('#####################')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgpu",
   "language": "python",
   "name": "pgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
